#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•è¯¦ç»†AIæ‰¹æ”¹åŠŸèƒ½
"""

import json
import sys
import os

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from utils import load_conversational_chain
from grade import grade_exam

def test_detailed_grading():
    """æµ‹è¯•è¯¦ç»†çš„AIæ‰¹æ”¹åŠŸèƒ½"""
    
    print("ğŸš€ å¼€å§‹æµ‹è¯•è¯¦ç»†AIæ‰¹æ”¹åŠŸèƒ½...")
    
    # 1. åŠ è½½AIé“¾
    print("ğŸ“š æ­£åœ¨åŠ è½½AIæ¨¡å‹...")
    qa_chain = load_conversational_chain()
    print("âœ… AIæ¨¡å‹åŠ è½½å®Œæˆ")
    
    # 2. å‡†å¤‡æµ‹è¯•æ•°æ®
    test_questions = [
        {
            'id': 1,
            'type': 'choice',
            'question_text': 'ä»€ä¹ˆæ˜¯æ·±åº¦å­¦ä¹ ï¼Ÿ',
            'options': ['A. æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªåˆ†æ”¯', 'B. æ•°æ®æŒ–æ˜æŠ€æœ¯', 'C. ç»Ÿè®¡å­¦æ–¹æ³•', 'D. ç¼–ç¨‹è¯­è¨€'],
            'answer': 'A',
            'score': 5
        },
        {
            'id': 2,
            'type': 'subjective',
            'question_text': 'è¯·è§£é‡Šç¥ç»ç½‘ç»œçš„å·¥ä½œåŸç†',
            'answer': 'ç¥ç»ç½‘ç»œé€šè¿‡å¤šå±‚èŠ‚ç‚¹å¤„ç†ä¿¡æ¯ï¼Œæ¯ä¸ªèŠ‚ç‚¹æ¥æ”¶è¾“å…¥ï¼Œè¿›è¡ŒåŠ æƒæ±‚å’Œï¼Œç„¶åé€šè¿‡æ¿€æ´»å‡½æ•°è¾“å‡ºç»“æœã€‚',
            'score': 10
        },
        {
            'id': 3,
            'type': 'choice',
            'question_text': 'ä»¥ä¸‹å“ªä¸ªä¸æ˜¯æœºå™¨å­¦ä¹ çš„ä¸»è¦ç±»å‹ï¼Ÿ',
            'options': ['A. ç›‘ç£å­¦ä¹ ', 'B. æ— ç›‘ç£å­¦ä¹ ', 'C. å¼ºåŒ–å­¦ä¹ ', 'D. é‡å­å­¦ä¹ '],
            'answer': 'D',
            'score': 5
        }
    ]
    
    test_answers = [
        {'question_id': 1, 'student_answer': 'B'},  # é”™è¯¯ç­”æ¡ˆ
        {'question_id': 2, 'student_answer': 'ç¥ç»ç½‘ç»œæ˜¯æ¨¡ä»¿äººè„‘çš„è®¡ç®—æ¨¡å‹ï¼Œé€šè¿‡å±‚å±‚å¤„ç†å®ç°æ™ºèƒ½'},  # ç®€å•ä½†åŸºæœ¬æ­£ç¡®çš„ç­”æ¡ˆ
        {'question_id': 3, 'student_answer': 'D'}   # æ­£ç¡®ç­”æ¡ˆ
    ]
    
    print("ğŸ“ æµ‹è¯•é¢˜ç›®ï¼š")
    for q in test_questions:
        # æ‰¾åˆ°å¯¹åº”çš„å­¦ç”Ÿç­”æ¡ˆ
        student_answer = next((ans['student_answer'] for ans in test_answers if ans['question_id'] == q['id']), "")

        print(f"  é¢˜ç›®{q['id']}: {q['question_text']}")
        if q['type'] == 'choice':
            print(f"    é€‰é¡¹: {q['options']}")
            print(f"    æ ‡å‡†ç­”æ¡ˆ: {q['answer']}")
            print(f"    å­¦ç”Ÿç­”æ¡ˆ: {student_answer}")
        else:
            print(f"    æ ‡å‡†ç­”æ¡ˆ: {q['answer']}")
            print(f"    å­¦ç”Ÿç­”æ¡ˆ: {student_answer}")
        print()
    
    # 3. è°ƒç”¨æ‰¹æ”¹å‡½æ•°
    print("ğŸ¤– æ­£åœ¨è¿›è¡ŒAIæ‰¹æ”¹...")
    try:
        results = grade_exam(test_questions, test_answers, qa_chain)
        
        if results:
            print("âœ… æ‰¹æ”¹å®Œæˆï¼è¯¦ç»†ç»“æœï¼š")
            print("=" * 80)
            
            for result in results:
                print(f"\nğŸ“‹ é¢˜ç›® {result['question_id']}:")
                print(f"   å¾—åˆ†: {result['score']}/{result['max_score']}")
                print(f"   çŸ¥è¯†ç‚¹: {result['knowledge_point']}")
                print(f"   è¯¦ç»†åé¦ˆ:")
                print(f"   {result['feedback']}")
                print("-" * 60)
            
            # 4. ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
            with open('detailed_grading_results.json', 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
            print(f"\nğŸ’¾ è¯¦ç»†æ‰¹æ”¹ç»“æœå·²ä¿å­˜åˆ° detailed_grading_results.json")
            
            # 5. è®¡ç®—æ€»åˆ†
            total_score = sum(r['score'] for r in results)
            max_total = sum(r['max_score'] for r in results)
            print(f"\nğŸ“Š æ€»åˆ†ç»Ÿè®¡: {total_score}/{max_total} ({total_score/max_total*100:.1f}%)")
            
        else:
            print("âŒ æ‰¹æ”¹å¤±è´¥ï¼Œæœªè·å¾—æœ‰æ•ˆç»“æœ")
            
    except Exception as e:
        print(f"âŒ æ‰¹æ”¹è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    test_detailed_grading()
