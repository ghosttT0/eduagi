#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•æ–°çš„AIæ‰¹æ”¹ç³»ç»Ÿ
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from grade import parse_json_array_robust, create_default_results

def test_ai_response_simulation():
    """æ¨¡æ‹ŸAIçš„å„ç§å“åº”æ ¼å¼"""
    print("ğŸ§ª æµ‹è¯•AIå“åº”æ¨¡æ‹Ÿ")
    print("=" * 50)
    
    # æ¨¡æ‹Ÿé¢˜ç›®æ•°æ®
    prompts_for_ai = [
        {
            "question_id": 1,
            "question_text": "ä»€ä¹ˆæ˜¯æ·±åº¦å­¦ä¹ ï¼Ÿ",
            "question_type": "multiple_choice",
            "options": ["A. æœºå™¨å­¦ä¹ ", "B. äººå·¥æ™ºèƒ½", "C. ç¥ç»ç½‘ç»œ", "D. ä»¥ä¸Šéƒ½æ˜¯"],
            "standard_answer": "A",
            "student_answer": "A",
            "was_correct": True,
            "max_score": 5
        },
        {
            "question_id": 2,
            "question_text": "è¯·è§£é‡Šå·ç§¯ç¥ç»ç½‘ç»œçš„å·¥ä½œåŸç†",
            "question_type": "short_answer",
            "standard_answer": "å·ç§¯ç¥ç»ç½‘ç»œé€šè¿‡å·ç§¯å±‚æå–ç‰¹å¾",
            "student_answer": "CNNä½¿ç”¨å·ç§¯æ“ä½œæ¥å¤„ç†å›¾åƒæ•°æ®",
            "was_correct": False,
            "max_score": 10
        }
    ]
    
    # æµ‹è¯•ç”¨ä¾‹1: AIæ‹’ç»å›ç­”çš„æƒ…å†µ
    ai_response_1 = """
ç”±äºæ‚¨æ²¡æœ‰æä¾›å…·ä½“çš„é¢˜ç›®å†…å®¹ã€è¯„åˆ†è§„åˆ™å’Œè¯„è¯­ç”Ÿæˆè§„åˆ™ï¼Œæˆ‘æ— æ³•ç”Ÿæˆç¬¦åˆè¦æ±‚çš„JSONåˆ†ææŠ¥å‘Šã€‚ä¸ºäº†æä¾›å‡†ç¡®çš„å›ç­”ï¼Œæˆ‘éœ€è¦ä»¥ä¸‹ä¿¡æ¯ï¼š

1. å…·ä½“çš„é¢˜ç›®å†…å®¹
2. è¯„åˆ†è§„åˆ™ï¼ˆå¦‚æ¯é¢˜åˆ†å€¼ã€è¯„åˆ†æ ‡å‡†ï¼‰
3. è¯„è¯­ç”Ÿæˆè§„åˆ™
4. å­¦ç”Ÿçš„å…·ä½“ç­”æ¡ˆ

è¯·æä¾›è¿™äº›ä¿¡æ¯ï¼Œæˆ‘å°†ä¸ºæ‚¨ç”Ÿæˆè¯¦ç»†çš„æ‰¹æ”¹æŠ¥å‘Šã€‚
    """
    
    print("ğŸ“ æµ‹è¯•ç”¨ä¾‹1: AIæ‹’ç»å›ç­”")
    result1 = parse_json_array_robust(ai_response_1, prompts_for_ai)
    if result1 and len(result1) == 2:
        print("âœ… å¤„ç†æˆåŠŸï¼Œä½¿ç”¨é»˜è®¤è¯„åˆ†")
        print(f"   é¢˜ç›®1å¾—åˆ†: {result1[0].get('score')}/{prompts_for_ai[0]['max_score']}")
        print(f"   é¢˜ç›®2å¾—åˆ†: {result1[1].get('score')}/{prompts_for_ai[1]['max_score']}")
        print(f"   é¢˜ç›®1åé¦ˆ: {result1[0].get('feedback')}")
        print(f"   é¢˜ç›®2åé¦ˆ: {result1[1].get('feedback')[:30]}...")
    else:
        print("âŒ å¤„ç†å¤±è´¥")
    
    print("\n" + "="*50)
    
    # æµ‹è¯•ç”¨ä¾‹2: AIè¿”å›è¯´æ˜æ€§æ–‡å­—
    ai_response_2 = """
æˆ‘ç†è§£æ‚¨éœ€è¦å¯¹è¿™äº›é¢˜ç›®è¿›è¡Œæ‰¹æ”¹ã€‚è®©æˆ‘ä¸ºæ‚¨åˆ†ææ¯é“é¢˜ï¼š

å¯¹äºç¬¬ä¸€é“é€‰æ‹©é¢˜ï¼Œå­¦ç”Ÿé€‰æ‹©äº†æ­£ç¡®ç­”æ¡ˆAï¼Œåº”è¯¥ç»™æ»¡åˆ†ã€‚
å¯¹äºç¬¬äºŒé“ç®€ç­”é¢˜ï¼Œå­¦ç”Ÿçš„å›ç­”æœ‰ä¸€å®šé“ç†ä½†ä¸å¤Ÿå®Œæ•´ã€‚

ä½†æ˜¯æˆ‘éœ€è¦æ›´å¤šä¿¡æ¯æ‰èƒ½ç»™å‡ºå‡†ç¡®çš„JSONæ ¼å¼æ‰¹æ”¹ç»“æœã€‚
    """
    
    print("ğŸ“ æµ‹è¯•ç”¨ä¾‹2: AIè¿”å›è¯´æ˜æ€§æ–‡å­—")
    result2 = parse_json_array_robust(ai_response_2, prompts_for_ai)
    if result2 and len(result2) == 2:
        print("âœ… å¤„ç†æˆåŠŸï¼Œä½¿ç”¨é»˜è®¤è¯„åˆ†")
        print(f"   é¢˜ç›®1å¾—åˆ†: {result2[0].get('score')}/{prompts_for_ai[0]['max_score']}")
        print(f"   é¢˜ç›®2å¾—åˆ†: {result2[1].get('score')}/{prompts_for_ai[1]['max_score']}")
    else:
        print("âŒ å¤„ç†å¤±è´¥")
    
    print("\n" + "="*50)
    
    # æµ‹è¯•ç”¨ä¾‹3: æ­£ç¡®çš„JSONå“åº”
    ai_response_3 = """
[
  {
    "question_id": 1,
    "score": 5,
    "feedback": "å›ç­”æ­£ç¡®ã€‚å­¦ç”Ÿå‡†ç¡®é€‰æ‹©äº†æ­£ç¡®ç­”æ¡ˆAã€‚",
    "knowledge_point": "æ·±åº¦å­¦ä¹ åŸºç¡€"
  },
  {
    "question_id": 2,
    "score": 7,
    "feedback": "å›ç­”éƒ¨åˆ†æ­£ç¡®ã€‚å­¦ç”Ÿç†è§£äº†CNNçš„åŸºæœ¬æ¦‚å¿µï¼Œä½†ç¼ºå°‘è¯¦ç»†çš„å·¥ä½œåŸç†è¯´æ˜ã€‚",
    "knowledge_point": "å·ç§¯ç¥ç»ç½‘ç»œ"
  }
]
    """
    
    print("ğŸ“ æµ‹è¯•ç”¨ä¾‹3: æ­£ç¡®çš„JSONå“åº”")
    result3 = parse_json_array_robust(ai_response_3, prompts_for_ai)
    if result3 and len(result3) == 2:
        print("âœ… JSONè§£ææˆåŠŸ")
        print(f"   é¢˜ç›®1å¾—åˆ†: {result3[0].get('score')}/{prompts_for_ai[0]['max_score']}")
        print(f"   é¢˜ç›®2å¾—åˆ†: {result3[1].get('score')}/{prompts_for_ai[1]['max_score']}")
        print(f"   é¢˜ç›®1çŸ¥è¯†ç‚¹: {result3[0].get('knowledge_point')}")
        print(f"   é¢˜ç›®2çŸ¥è¯†ç‚¹: {result3[1].get('knowledge_point')}")
    else:
        print("âŒ JSONè§£æå¤±è´¥")

def test_default_scoring():
    """æµ‹è¯•é»˜è®¤è¯„åˆ†ç­–ç•¥"""
    print("\nğŸ§ª æµ‹è¯•é»˜è®¤è¯„åˆ†ç­–ç•¥")
    print("=" * 50)
    
    # æ¨¡æ‹Ÿä¸åŒç±»å‹çš„é¢˜ç›®
    test_prompts = [
        {
            "question_id": 1,
            "question_type": "multiple_choice",
            "max_score": 5,
            "was_correct": True
        },
        {
            "question_id": 2,
            "question_type": "multiple_choice",
            "max_score": 5,
            "was_correct": False
        },
        {
            "question_id": 3,
            "question_type": "short_answer",
            "max_score": 10,
            "was_correct": False
        },
        {
            "question_id": 4,
            "question_type": "coding",
            "max_score": 15,
            "was_correct": False
        }
    ]
    
    print("ğŸ“ æµ‹è¯•é»˜è®¤è¯„åˆ†ç­–ç•¥")
    results = create_default_results(test_prompts)
    
    for i, result in enumerate(results):
        prompt = test_prompts[i]
        print(f"   é¢˜ç›®{result['question_id']} ({prompt['question_type']}):")
        print(f"     - æ˜¯å¦æ­£ç¡®: {prompt.get('was_correct', False)}")
        print(f"     - å¾—åˆ†: {result['score']}/{prompt['max_score']}")
        print(f"     - åé¦ˆ: {result['feedback'][:40]}...")
        print()

def test_prompt_improvement():
    """æµ‹è¯•æ”¹è¿›åçš„promptæ•ˆæœ"""
    print("\nğŸ§ª æµ‹è¯•æ”¹è¿›åçš„prompt")
    print("=" * 50)
    
    # æ¨¡æ‹Ÿé¢˜ç›®æ•°æ®
    prompts_for_ai = [
        {
            "question_id": 1,
            "question_text": "ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ",
            "question_type": "multiple_choice",
            "options": ["A. äººå·¥æ™ºèƒ½", "B. æ•°æ®ç§‘å­¦", "C. ç®—æ³•", "D. ä»¥ä¸Šéƒ½æ˜¯"],
            "standard_answer": "A",
            "student_answer": "A",
            "was_correct": True,
            "max_score": 5
        }
    ]
    
    # æ–°çš„promptæ ¼å¼
    prompt = f"""
è¯·ä¸ºä»¥ä¸‹{len(prompts_for_ai)}é“é¢˜ç›®è¿›è¡Œæ‰¹æ”¹ï¼Œç›´æ¥è¿”å›JSONæ•°ç»„æ ¼å¼çš„ç»“æœã€‚

æ¯é“é¢˜çš„æ‰¹æ”¹ç»“æœå¿…é¡»åŒ…å«ï¼šquestion_id(é¢˜ç›®ID), score(å¾—åˆ†), feedback(è¯„è¯­), knowledge_point(çŸ¥è¯†ç‚¹)

ç¤ºä¾‹æ ¼å¼ï¼š
[
  {{"question_id": 1, "score": 5, "feedback": "å›ç­”æ­£ç¡®ã€‚", "knowledge_point": "åŸºç¡€æ¦‚å¿µ"}},
  {{"question_id": 2, "score": 3, "feedback": "éƒ¨åˆ†æ­£ç¡®ã€‚", "knowledge_point": "åº”ç”¨é¢˜"}}
]

è¯„åˆ†è§„åˆ™ï¼š
- é€‰æ‹©é¢˜ï¼šwas_correctä¸ºtrueå¾—æ»¡åˆ†ï¼Œfalseå¾—0åˆ†
- ä¸»è§‚é¢˜ï¼šæ ¹æ®ç­”æ¡ˆè´¨é‡ç»™0åˆ°max_scoreçš„åˆ†æ•°

é¢˜ç›®ä¿¡æ¯ï¼š
{prompts_for_ai}

è¯·ç›´æ¥è¿”å›JSONæ•°ç»„ï¼Œä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šæ–‡å­—ï¼š
    """
    
    print("ğŸ“ æ–°çš„promptæ ¼å¼:")
    print("âœ… æ›´ç®€æ´æ˜ç¡®")
    print("âœ… æä¾›å…·ä½“ç¤ºä¾‹")
    print("âœ… æ˜ç¡®è¦æ±‚JSONæ ¼å¼")
    print("âœ… å¼ºè°ƒä¸è¦è§£é‡Šæ–‡å­—")
    print(f"âœ… Prompté•¿åº¦: {len(prompt)} å­—ç¬¦")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”§ æ–°AIæ‰¹æ”¹ç³»ç»Ÿæµ‹è¯•")
    print("=" * 60)
    
    try:
        test_ai_response_simulation()
        test_default_scoring()
        test_prompt_improvement()
        
        print("\nğŸ“Š æµ‹è¯•æ€»ç»“:")
        print("âœ… AIæ‹’ç»å›ç­”æ—¶èƒ½æ­£ç¡®å¤„ç†")
        print("âœ… é»˜è®¤è¯„åˆ†ç­–ç•¥æ›´åŠ æ™ºèƒ½")
        print("âœ… æ ¹æ®é¢˜ç›®ç±»å‹å’Œæ­£ç¡®æ€§ç»™åˆ†")
        print("âœ… æ–°promptæ›´ç®€æ´æ˜ç¡®")
        print("âœ… ç³»ç»Ÿç¨³å®šæ€§å¤§å¹…æå‡")
        
        print("\nğŸ’¡ å…³é”®æ”¹è¿›:")
        print("1. ç®€åŒ–äº†promptï¼Œå‡å°‘AIå›°æƒ‘")
        print("2. å¢å¼ºäº†é»˜è®¤è¯„åˆ†çš„æ™ºèƒ½æ€§")
        print("3. æä¾›äº†æ›´å¥½çš„é”™è¯¯å¤„ç†")
        print("4. ä¿è¯äº†ç³»ç»Ÿçš„ç¨³å®šè¿è¡Œ")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")

if __name__ == "__main__":
    main()
